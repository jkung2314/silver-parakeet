Team:

Samin Akter
Jonathan Kung
Steven Suh
Emma Wong

CMPS 111 Spring 2019
Asg 2 - DESIGN DOC

OVERVIEW

	The purpose of this assignment is to modify the FreeBSD scheduler to run priority queues and implement splatter 
scheduling.
	

GOALS

	As outlined in the assignment pdf itself, we need to support the following cases:

	- Case 1: FIFO queues and current FreeBSD scheduling
	- Case 2: Priority queues and current FreeBSD scheduling
	- Case 3: FIFO queues and splatter scheduling
	- Case 4: Priority queues and splatter scheduling

	And make sure that the following requirements are met:

	- Random generator should perform the same when tested with seed values
	- Random numbers should be uniformly distributed
	- Write benchmarks to compare performance statistics of different cases
		- Runtime	
		- Page faults
		- Memory efficiency
		- Overhead
	- Include bar graph to show performance comparison among the 4 cases


PROCESS

	For this assignment we spent the most time figuring out how the kernel worked before implementing priority queues
and splatter scheduling.

	There were somethings that we ended up not having to alter given our approach such as the nice() call and the 
sched_ule.c file. We ended up just making modifications to the kern_switch.c file.


ARCHITECTURE

	In order to switch between cases we implemented a kernel flag called CMPS_111_SCHED which set to 1 represents case 
1. In the runq_add function, we check which case was requested.

	Before doing anything, we check if the thread is a user thread using its id number.
	
	If we are given case 3 or 4 we know that splatter scheduling is required so the variable pri is set to return a 
random runq within its given type. If CMPS_111_SCHED is 1 or 2, we select the runq based on the thread's priority
(as is the base case). We set the runq using the function runq_setbit.

	Once we know which runq we want to add the thread to, we check CMPS_111_SCHED again to see whether we want to 
add the thread to the queue in FIFO or priority order.

	For the priority queue implementation, we use a for each loop to go through the threads in the runq. If the 
priority of the thread being added is greater than the current thread, the new thread is inserted before the
current thread. This gives us a queue in which the first thread has the greatest priority. If the queue is empty
the thread is simply placed at the head. 


ANALYSIS

Case 1:
	- Runtime:
	- Page faults:
	- Memory efficiency:
	- Overhead:

Case 2:
	- Runtime:
	- Page faults:
	- Memory efficiency:
	- Overhead:

Case 3:
	- Runtime:
	- Page faults:
	- Memory efficiency:
	- Overhead:

Case 4:
	- Runtime:
	- Page faults:
	- Memory efficiency:
	- Overhead:


	
